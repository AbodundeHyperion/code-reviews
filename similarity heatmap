
import spacy
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load spaCy model
nlp = spacy.load("en_core_web_md")

# Define a list of words for similarity comparison
words = ["cat", "dog", "banana", "apple", "car", "bike"]

# Compute similarity scores between words
similarity_matrix = np.zeros((len(words), len(words)))
for i, word1 in enumerate(words):
for j, word2 in enumerate(words):
similarity_matrix[i, j] = nlp(word1).similarity(nlp(word2))

# Plot similarity score heatmap
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(similarity_matrix, annot=True, xticklabels=words, yticklabels=words, cmap="YlGnBu")
plt.title("Semantic Similarity Heatmap")
plt.xlabel("Words")
plt.ylabel("Words")
plt.show()

# Visualize word vector embeddings
word_vectors = np.array([nlp(word).vector for word in words])

# Perform dimensionality reduction using PCA
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
word_embeddings_2d = pca.fit_transform(word_vectors)

# Plot word vector embeddings
plt.figure(figsize=(8, 6))
plt.scatter(word_embeddings_2d[:, 0], word_embeddings_2d[:, 1], c="blue")
for i, word in enumerate(words):
plt.annotate(word, (word_embeddings_2d[i, 0], word_embeddings_2d[i, 1]))
plt.title("Word Vector Embeddings Visualization")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.show()
